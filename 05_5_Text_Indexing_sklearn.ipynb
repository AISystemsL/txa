{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "05.5 - Text Indexing - sklearn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ITvyYx54g5C"
      },
      "source": [
        "## Indexing with sklearn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1J4daS74g5D"
      },
      "source": [
        "## loading a dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-h1T5rE4g5E"
      },
      "source": [
        "import urllib.request\n",
        "import os\n",
        "\n",
        "def download_file(url,local_file, force=False):\n",
        "    \"\"\"\n",
        "    Helper function to download a file and store it locally\n",
        "    \"\"\"\n",
        "    if not os.path.exists(local_file) or force:\n",
        "        print('Downloading',url,'to',local_file)\n",
        "        with urllib.request.urlopen(url) as opener, \\\n",
        "             open(local_file, mode='w', encoding='utf-8') as outfile:\n",
        "                    outfile.write(opener.read().decode('utf-8'))\n",
        "    else:\n",
        "        print(local_file,'already downloaded')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO0fkbdn4g5J"
      },
      "source": [
        "train_file = 'news_en_train.txt'\n",
        "train_url='http://www.esuli.it/demo/data/news_en_train.csv'\n",
        "test_file = 'news_en_test.txt'\n",
        "test_url = 'http://www.esuli.it/demo/data/news_en_test.csv'\n",
        "delimiter = ','\n",
        "\n",
        "download_file(train_url, train_file)\n",
        "download_file(test_url, test_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3zwOQQ64g5O"
      },
      "source": [
        "import csv\n",
        "x_train = list()\n",
        "y_train = list()\n",
        "with open(train_file, encoding='utf-8', newline='') as infile:\n",
        "    reader = csv.reader(infile, delimiter=delimiter)\n",
        "    for row in reader:\n",
        "        x_train.append(row[0])\n",
        "        y_train.append(row[1])\n",
        "\n",
        "x_test = list()\n",
        "y_test = list()\n",
        "with open(test_file, encoding='utf-8', newline='') as infile:\n",
        "    reader = csv.reader(infile, delimiter=delimiter)\n",
        "    for row in reader:\n",
        "        x_test.append(row[0])\n",
        "        y_test.append(row[1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70X8gxqX4g5T"
      },
      "source": [
        "len(x_train),len(y_train),len(x_test),len(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62X87ZY84g5Z"
      },
      "source": [
        "set(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r42x4ICg4g5e"
      },
      "source": [
        "sample_idx = 10\n",
        "x_train[sample_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1olVl9d54g5j"
      },
      "source": [
        "y_train[sample_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Sw_15ILDQ8F"
      },
      "source": [
        "# Binary classification\n",
        "\n",
        "This is a multi-class single-label dataset.\n",
        "We start with a simpler binary classification problem, e.g., economy vs not economy.\n",
        "\n",
        "Just to make a choice, we use as the reference label the one of the example in the cell above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQtlnmjUDmvm"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# numpy implements many useful and powerful vector manipulation tools\n",
        "# here I'm using it to quickly create a True,False vector corresponding\n",
        "# to the original values being equal to our label of interest or not\n",
        "# i.e., binary labels\n",
        "\n",
        "y_train_bin = np.asarray(y_train)==y_train[sample_idx]\n",
        "y_test_bin = np.asarray(y_test)==y_train[sample_idx]\n",
        "y_train_bin,y_test_bin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwMzU9JR4g5o"
      },
      "source": [
        "## Building the pipeline by hand"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c26tzsE4g5p"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VWoWZd_7uIe"
      },
      "source": [
        "## Tokenization\n",
        "\n",
        "Try the following two cells removing the min_df parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk5Cvvyc4g5r"
      },
      "source": [
        "vect = CountVectorizer(min_df=5)  # tokenization and frequency count\n",
        "\n",
        "print('fit')\n",
        "vect.fit(x_train)\n",
        "print('transform')\n",
        "X_train_tok = vect.transform(x_train)\n",
        "print('done')\n",
        "\n",
        "# the two steps above can be condensed in a single step that processes train\n",
        "# data only once.\n",
        "\n",
        "# print('fit_transform')\n",
        "# X_train_tok = vect.fit_transform(x_train)\n",
        "# print('done')\n",
        "\n",
        "X_test_tok =vect.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1x3p0T271jX"
      },
      "source": [
        "len(vect.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxwBNFrT8UQ0"
      },
      "source": [
        "vect.vocabulary_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipJykPr14g5u"
      },
      "source": [
        "vect.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2lgD7Y04g5x"
      },
      "source": [
        "X_train_tok[0,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mik5K904g51"
      },
      "source": [
        "print(X_train_tok[0,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nopxC-YP4g54"
      },
      "source": [
        "Some scikit-learn modules implement an inverse_transform method to reconstruct input from their output.\n",
        "Let's print out the feature names and their frequency for a document. Note that frequency info is lost."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjh8ymz_4g55"
      },
      "source": [
        "vect.inverse_transform(X_train_tok[0,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FziDW-YRBGRP"
      },
      "source": [
        "Let's attach frequency data to features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gU1QgQx88iR"
      },
      "source": [
        "for feat,freq in zip(vect.inverse_transform(X_train_tok[0,:])[0],X_train_tok[0,:].data):\n",
        "  print(feat,freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHFnwDZO7Ucs"
      },
      "source": [
        "## Feature selection\n",
        "\n",
        "This is the first element where we use the labels, because it is a supervised method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G6-jLSx4g5-"
      },
      "source": [
        "bin_sel = SelectKBest(chi2, k=5000)  # feature selection\n",
        "bin_sel.fit(X_train_tok,y_train_bin)\n",
        "X_train_sel_bin = bin_sel.transform(X_train_tok)\n",
        "X_test_sel_bin = bin_sel.transform(X_test_tok)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_tPAeRm4g6C"
      },
      "source": [
        "bin_sel.get_support()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_PneJ3w4g6G"
      },
      "source": [
        "X_train_sel_bin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcZ-oyJYBlTI"
      },
      "source": [
        "X_train_sel_bin[0,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVS4Y3cr4g6L"
      },
      "source": [
        "print(X_train_sel_bin[0,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Za9mLr17DRm"
      },
      "source": [
        "The feature selection module has an inverse transform method so that we can map selected feature back to the original large feature space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBK9OqB0673F"
      },
      "source": [
        "bin_sel.inverse_transform(X_train_sel_bin[0,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDR_BxTG7Ov-"
      },
      "source": [
        "print(vect.inverse_transform(bin_sel.inverse_transform(X_train_sel_bin[0,:])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jqGqAmC7P1c"
      },
      "source": [
        "## Weighting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdGwiuCW4g6P"
      },
      "source": [
        "tfidf = TfidfTransformer()  # weighting\n",
        "tfidf.fit(X_train_sel_bin)\n",
        "X_train_vec_bin = tfidf.transform(X_train_sel_bin)\n",
        "X_test_vec_bin =tfidf.transform(X_test_sel_bin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hL7RI16F4g6R"
      },
      "source": [
        "print(X_train_vec_bin[0,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQhAOByVBtId"
      },
      "source": [
        "for feat,weight,freq in zip(vect.inverse_transform(bin_sel.inverse_transform(X_train_vec_bin[0,:]))[0],X_train_vec_bin[0,:].data,X_train_sel_bin[0,:].data):\n",
        "  print(feat,weight,freq)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}